# 理论
- 初始化能够有效地避免对称现象（数值一样）
	- 无法学习复杂的特征
- 减少梯度爆炸和梯度消失的发生

# 初始化种类
## Xavier初始化
- 用于tanh
$$\large Var(w_i) = {{2}\over{n_{in}+n_{out}}}$$
- 正态分布初始化
$$\large N(0,{2\over{n_{in}+n_{out}}})$$
- 均匀分布初始化
$$\large U({-\sqrt{{6}\over{n_{in}+n_{out}}}},{\sqrt{{6}\over{n_{in}+n_{out}}}})$$
## KaiMing初始化
- 用于ReLU
$$\large Var(w_i) = {{2}\over{n(1+\alpha^2)}}$$
- 正态分布初始化
$$\large N(0,{{2}\over{n(1+\alpha^2)}})$$
- 均匀分布初始化
$$U(-\sqrt{{{2}\over{n(1+\alpha^2)}}},\sqrt{{{2}\over{n(1+\alpha^2)}}})$$

# 参考文献
- [[5分钟深度学习] #04 参数初始化](https://www.bilibili.com/video/BV1r94y1Q7eG/?spm_id_from=333.788&vd_source=82cc9f8195ff57b14f4f1d470824ef31)
- [[5分钟深度学习] #05 参数初始化 再硬核一点！](https://www.bilibili.com/video/BV1PF411K7nb/?spm_id_from=333.788&vd_source=82cc9f8195ff57b14f4f1d470824ef31)

