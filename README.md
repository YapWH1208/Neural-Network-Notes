[Eng](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/README.md) / [中文](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/README_CN.md)

# Neural-Network-Notes
Neural Network Notes

# Content
- [Argmax vs max](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/Argmax%20vs%20max.md)
- [Requirements.txt](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/Requirements.txt.md)
## Algorithm
- [Attention Mechanism](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/AI%E7%AE%97%E6%B3%95/Attention%20Mechanism.md)
- [线性回归](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/AI%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.md)

## Techniques
- [Early Stopping](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E6%8A%80%E5%B7%A7/Early%20Stopping/Early%20Stopping.md)
- [Learning Rate Scheduler](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E6%8A%80%E5%B7%A7/Learning%20Rate%20Schedular/Learning%20Rate%20Schedular.md)
- [调参指南](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E6%8A%80%E5%B7%A7/Hyperparameter%20Tuning/%E8%B0%83%E5%8F%82%E6%8C%87%E5%8D%97.md)
- [Logger](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E6%8A%80%E5%B7%A7/Logger.md)
- [Seed](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E6%8A%80%E5%B7%A7/Seed.md)

## Neural Network
- [Optimizer](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E4%BC%98%E5%8C%96%E5%99%A8/%E4%BC%98%E5%8C%96%E5%99%A8/%E4%BC%98%E5%8C%96%E5%99%A8.md)
- [Common Neural Network Introduction](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Common%20Neural%20Networks%20Introduction.md)
### Other
- [Why FC Layer?](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%85%B6%E4%BB%96/Why%20Fully-connected%20layer.md)
- [隐藏层节点数的影响](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%85%B6%E4%BB%96/%E9%9A%90%E8%97%8F%E5%B1%82%E8%8A%82%E7%82%B9%E6%95%B0%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E7%BB%93%E6%9E%9C.md)
### Techniques
- [Cross-Validation](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%8A%80%E5%B7%A7/Cross-Validation%E5%B9%B2%E5%98%9B%E7%94%A8%E7%9A%84%EF%BC%9F.md)
- [初始化](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%8A%80%E5%B7%A7/%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9C%9F%E6%9C%89%E7%94%A8%EF%BC%9F.md)
- [批量归一化](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%8A%80%E5%B7%A7/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E9%9D%9E%E5%B8%B8%E5%BC%BA.md)
### Metric
- [Loss Function](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%8C%87%E6%A0%87/Loss%20Function.md)
- [Metric](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%8C%87%E6%A0%87/Metric.md)
### Activation Function
- [ReLU](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/ReLU%E7%9A%84%E6%97%8F%E8%B0%B1.md)
- [Sigmoid vs Softmax](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/Sigmoid%E5%92%8CSoftmax%E7%9A%84%E6%81%A9%E6%80%A8%E6%83%85%E4%BB%87.md)
- [ReLU,Sigmoid,Tanh](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/%E4%B8%89%E4%BA%BA%E8%A1%8C%E5%BF%85%E6%9C%89%E6%88%91%E5%B8%88.md)
- [Why Activation Function](https://github.com/YapWH1208/Neural-Network-Notes/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%9F.md)
